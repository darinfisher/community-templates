apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: priceless-knuth-725001
spec:
    color: '#8e1fc3'
    name: kafka
---
apiVersion: influxdata.com/v2alpha1
kind: Variable
metadata:
    name: burfect-bohr-725001
spec:
    language: flux
    name: broker_host
    query: |-
        import "influxdata/influxdb/v1"
        all_data = buckets() |> limit(n:1) |> set(key: "_value", value: "*") |> keep(columns:["_value"])
        hosts = v1.measurementTagValues(bucket: v.bucket, measurement: "cpu", tag: "host")
        union(tables: [all_data, hosts]) |> sort()
    type: query
---
apiVersion: influxdata.com/v2alpha1
kind: Variable
metadata:
    name: friendly-montalcini-325001
spec:
    language: flux
    name: kafka_topic
    query: |-
        import "influxdata/influxdb/v1"

        all_data = buckets() |> limit(n:1) |> set(key: "_value", value: "*") |> keep(columns:["_value"])
        brokers = v1.measurementTagValues(bucket: v.bucket, measurement: "kafka_topics", tag: "topic")
        union(tables: [all_data, brokers]) |> sort()
    type: query
---
apiVersion: influxdata.com/v2alpha1
kind: Variable
metadata:
    name: xenodochial-khorana-325003
spec:
    language: flux
    name: bucket
    query: |-
        buckets()
          |> filter(fn: (r) => r.name !~ /^_/)
          |> rename(columns: {name: "_value"})
          |> keep(columns: ["_value"])
    type: query
---
apiVersion: influxdata.com/v2alpha1
kind: Dashboard
metadata:
    name: realistic-hugle-325001
spec:
    associations:
      - kind: Label
        name: priceless-knuth-725001
    charts:
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 0
        height: 1
        kind: Single_Stat
        name: Controller State
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_controller")
                  |> filter(fn: (r) => r["_field"] == "ControllerState")
        width: 2
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Bytes in per topic per second
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "diskio" or r["_measurement"] == "kafka_topics")
                  |> filter(fn: (r) => r["_field"] == "BytesInPerSec")
                  |> filter(fn: (r) =>
                  (if v.kafka_topic == "*" then true
                    else r["topic"] == v.kafka_topic))
                  |> group(columns: ["topic"])
                  |> sort(columns: ["_time"])
                  |> derivative(unit: 1s, nonNegative: true, columns: ["_value"], timeColumn: "_time")
        shade: true
        width: 6
        xCol: _time
        yCol: _value
        yPos: 1
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Fetch Requests Per Topic Per Second
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_topics")
                  |> filter(fn: (r) => r["_field"] == "TotalFetchRequestsPerSec")
                  |> group(columns: ["topic"])
        shade: true
        width: 4
        xCol: _time
        yCol: _value
        yPos: 4
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: ZK Latency
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "zookeeper")
                  |> filter(fn: (r) => r["_field"] == "max_latency" or r["_field"] == "min_latency" or r["_field"] == "avg_latency")
        shade: true
        width: 6
        xCol: _time
        yCol: _value
        yPos: 7
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 0
        height: 1
        kind: Single_Stat
        name: Active Controller Count
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_controller")
                  |> filter(fn: (r) => r["_field"] == "ActiveControllerCount")
                  |> group(columns: ["host"])
                  |> last()
                  |> group()
                  |> sum()
        width: 2
        xPos: 2
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 0
        height: 1
        kind: Single_Stat
        name: Underreplicated Partitions (total)
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_partition")
                  |> filter(fn: (r) => r["_field"] == "UnderReplicatedPartitions")
                  |> last()
                  |> group()
                  |> sum()
        width: 2
        xPos: 4
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "2"
            label: Bytes
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Bytes Per Minute Per Broker
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_requests")
                  |> filter(fn: (r) => r["_field"] == "BytesCount")
                  |> window(every: 1m)
                  |> derivative(unit: 1m, nonNegative: true, columns: ["_value"], timeColumn: "_time")
                  |> filter(fn: (r) =>
                		(if v.broker_host == "*" then true
                     else r["host"] == v.broker_host))
                  |> group(columns: ["host"])
                  |> sort(columns: ["_time"])
        shade: true
        width: 4
        xCol: _time
        xPos: 4
        yCol: _value
        yPos: 4
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 0
        height: 1
        kind: Single_Stat
        name: Underreplicated Partitions in v.kafka_topic
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_partition")
                  |> filter(fn: (r) => r["_field"] == "UnderReplicatedPartitions")
                  |> filter(fn: (r) => r.topic == v.kafka_topic)
                  |> last()
        width: 2
        xPos: 6
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Bytes per broker / sec
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_requests")
                  |> filter(fn: (r) => r["_field"] == "BytesCount")
                  |> filter(fn: (r) =>
                (if v.broker_host == "*" then true
                  else r["host"] == v.broker_host))
                  |> group(columns: ["host"])
                  |> sort(columns: ["_time"])
                  |> derivative(unit: 1s, nonNegative: true, columns: ["_value"], timeColumn: "_time")
        shade: true
        width: 6
        xCol: _time
        xPos: 6
        yCol: _value
        yPos: 1
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: ZK Alive Connections
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "zookeeper")
                  |> filter(fn: (r) => r["_field"] == "num_alive_connections")
        shade: true
        width: 6
        xCol: _time
        xPos: 6
        yCol: _value
        yPos: 7
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 0
        height: 1
        kind: Single_Stat
        name: LogEndOffset in v.kafka_topic
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_partition")
                  |> filter(fn: (r) => r["_field"] == "LogEndOffset")
                  |> filter(fn: (r) => r.topic == v.kafka_topic)
        width: 4
        xPos: 8
      - axes:
          - base: "2"
            name: y
            scale: linear
          - base: "10"
            name: x
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Errors per request
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_network")
                  |> filter(fn: (r) => r._field != "NONE")
                  |> group(columns: ["request"])
                  |> sort(columns: ["_time"])
                  |> derivative(unit: 1s, nonNegative: true, columns: ["_value"], timeColumn: "_time")
        shade: true
        width: 4
        xCol: _time
        xPos: 8
        yCol: _value
        yPos: 4
    name: Kafka Metrics
---
apiVersion: influxdata.com/v2alpha1
kind: Telegraf
metadata:
    name: blissful-ramanujan-b25001
spec:
    config: |
        [agent]

        interval = "10s"
        round_interval = true
        metric_batch_size = 1000
        metric_buffer_limit = 1000
        collection_jitter = "0s"
        flush_interval = "10s"
        flush_jitter = "0s"
        precision = ""
        debug = true
        quiet = false
        logfile = ""
        hostname = ""
        omit_hostname = false

        # Outputs

        [[outputs.influxdb_v2]]

        # urls = ["$INFLUX_HOST"]
        # urls = ["https://enb37b16zawnc.x.pipedream.net"]
        urls = ["https://enqkw5jnpufjr.x.pipedream.net"]
        token = "$INFLUX_TOKEN"
        organization = "$INFLUX_ORG"
        bucket = "$INFLUX_BUCKET"

        # [[outputs.file]]



        ###############################################################################
        #                            INPUT PLUGINS                                    #
        ###############################################################################

        # for more info on input plugins: https://github.com/influxdata/telegraf/tree/master/plugins/inputs

        [[inputs.cpu]]
        [[inputs.mem]]
        [[inputs.disk]]
        [[inputs.diskio]]
        [[inputs.net]]
        [[inputs.kernel]]
        [[inputs.swap]]
        [[inputs.processes]]

        [[inputs.jolokia2_agent]]
        default_tag_prefix = ""
        default_field_prefix = ""
        default_field_separator = "_"
        urls = ["$JOLOKIA_AGENT_URL"]
        tagexclude = ["jolokia_agent_url"]
        # [[inputs.jolokia2_agent.tagdrop]]
        #   jolokia_agent_url = "*"

        # (still have to add Type=DelayedOperationPurgatory)
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_replica_manager"
          mbean        = "kafka.server:type=ReplicaManager,name=*"
          paths        = ["Count"]
          field_name = "$1"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_replica_manager"
          mbean        = "kafka.server:type=ReplicaManager,name=PartitionCount"
          field_name   = "PartitionCount"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_replica_manager"
          mbean        = "kafka.server:type=ReplicaManager,name=LeaderCount"
          field_name   = "LeaderCount"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_replica_manager"
          mbean        = "kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions"
          field_name   = "UnderReplicatedPartitions"

        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_broker"
          mbean        = "kafka.server:type=kafka-metrics-count"
          field_name   = "kafka_metrics_count"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_broker"
          mbean        = "kafka.server:type=BrokerTopicMetrics,name=*"
          field_name   = "kafka_metrics_count"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_broker"
          mbean        = "kafka.server:type=DelayedOperationPurgatory,name=NumDelayedOperations,delayedOperation=*"
          field_name   = "$1"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_broker"
          mbean        = "kafka.server:type=Produce"
          field_name   = "ProduceQueueSize"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_topics"
          mbean        = "kafka.server:type=BrokerTopicMetrics,name=*,topic=*"
          paths        = ["Count"]
          field_name   = "$1"
          tag_keys     = ["topic"]
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_controller"
          mbean        = "kafka.controller:type=KafkaController,name=*"
          field_name   = "$1"

        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_network"
          mbean        = "kafka.network:type=RequestMetrics,name=ErrorsPerSec,request=*,error=*"
          paths        = ["Count"]
          tag_keys     = ["request"]
          field_name   = "$2"

        # from kafka.network
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_requests"
          mbean        = "kafka.network:type=RequestMetrics,name=RequestBytes,request=*"
          tag_keys     = ["request"]
          field_prefix = "Bytes"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_requests"
          mbean        = "kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request=*"
          tag_keys     = ["request"]
          field_prefix = "QueueTime"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_requests"
          mbean        = "kafka.network:type=RequestMetrics,name=RequestsPerSec,request=*,version=*"
          tag_keys     = ["request"]
          paths        = ["Count"]
          field_name   = "Count"

        # [[inputs.jolokia2_agent.metric]]
        #   name         = "kafka_controller"
        #   mbean        = "kafka.controller:type=KafkaController,name=*"


        [[inputs.jolokia2_agent.metric]]
          name       = "kafka_partition"
          mbean      = "kafka.log:name=*,partition=*,topic=*,type=Log"
          field_name = "$1"
          tag_keys   = ["topic", "partition"]
        [[inputs.jolokia2_agent.metric]]
          name       = "kafka_partition"
          mbean      = "kafka.cluster:name=UnderReplicated,partition=*,topic=*,type=Partition"
          field_name = "UnderReplicatedPartitions"
          tag_keys   = ["topic"]

        [[inputs.zookeeper]]

        # servers = ["$ZOOKEEPER_CONNECTION_STRING"]

        ## Timeout for metric collections from all servers.  Minimum timeout is "1s".
        # timeout = "5s"

        ## Optional TLS Config
        # enable_tls = true
        # tls_ca = "/etc/telegraf/ca.pem"
        # tls_cert = "/etc/telegraf/cert.pem"
        # tls_key = "/etc/telegraf/key.pem"
        ## If false, skip chain & host verification
        # insecure_skip_verify = true
    name: kafka-zk-jolokia
